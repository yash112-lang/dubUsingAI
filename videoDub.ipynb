{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0LxZxfjzoSZ",
        "outputId": "eac41cc8-c1e7-48a8-a68e-1fa04db1248e"
      },
      "source": [
        "# Installing Modules/Packages\n",
        "!pip install audiosegment\n",
        "!pip install --upgrade google-cloud-speech\n",
        "!pip install --upgrade google-cloud-texttospeech"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: audiosegment in /usr/local/lib/python3.7/dist-packages (0.23.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (from audiosegment) (0.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from audiosegment) (1.19.5)\n",
            "Requirement already satisfied: webrtcvad in /usr/local/lib/python3.7/dist-packages (from audiosegment) (2.0.10)\n",
            "Requirement already satisfied: google-cloud-speech in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (21.0)\n",
            "Requirement already satisfied: proto-plus>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (1.19.0)\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (1.26.3)\n",
            "Requirement already satisfied: libcst>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (0.3.20)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (1.34.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (2.23.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (1.53.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (3.17.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (2018.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (1.39.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (0.2.8)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-speech) (3.7.4.3)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-speech) (0.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.2 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-speech) (5.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-speech) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (3.0.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from typing-inspect>=0.4.0->libcst>=0.2.5->google-cloud-speech) (0.4.3)\n",
            "Requirement already satisfied: google-cloud-texttospeech in /usr/local/lib/python3.7/dist-packages (2.5.2)\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (1.26.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (21.0)\n",
            "Requirement already satisfied: proto-plus>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (1.19.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.53.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.34.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (3.17.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (57.4.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (2018.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.39.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (0.2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-texttospeech) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybMYRdz8z-9D"
      },
      "source": [
        "# Importing Modules/Packages\n",
        "from google.colab import drive\n",
        "from pydub import AudioSegment\n",
        "from google.cloud import speech_v1p1beta1 as speech\n",
        "from google.cloud.speech_v1 import types\n",
        "import os\n",
        "import io\n",
        "from scipy.io import wavfile\n",
        "import os\n",
        "import json\n",
        "from google.cloud import translate\n",
        "from google.cloud import texttospeech\n",
        "import html\n",
        "import shutil\n",
        "import tempfile\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, CompositeVideoClip\n",
        "from moviepy.video.tools.subtitles import SubtitlesClip, TextClip"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQiRMwHX0EaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de78f86b-e7b9-4fbc-f836-1e507c21188a"
      },
      "source": [
        "# connecting to google drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYLu1MAm0PJE"
      },
      "source": [
        "# Setting Credentials to access APIs\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/content/drive/My Drive/GCP/Speech-to-text.json\"\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/content/drive/My Drive/GCP/translationAPI.json'\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/content/drive/My Drive/GCP/text-to-speech-practice.json'"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f2WdIaX0WcC"
      },
      "source": [
        "# Extracting audio from Video\n",
        "def decode_audio(inFile, outFile):\n",
        "  '''\n",
        "    infile: input file path i.e. a\\b\\c.mp4\n",
        "    outfile: output path i.e. a\\b\\c.wav\n",
        "  '''\n",
        "  if not outFile[-4:] != \"wav\":\n",
        "    outFile += \".wav\"\n",
        "  AudioSegment.from_file(inFile).set_channels(1).export(outFile, format=\"wav\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxsOs0gO0m7V"
      },
      "source": [
        "def get_transcripts_json(gdrivePath, langCode, phraseHints=[], speakerCount=1, enhancedModel=None):\n",
        "    \"\"\"Transcribes audio files.\n",
        "    Args:\n",
        "        gdrivePath (String): path to file in cloud storage (i.e. \"/content/drive/My Drive/audio/clip.mp4\")\n",
        "        langCode (String): language code (i.e. \"en-US\", see https://cloud.google.com/speech-to-text/docs/languages)\n",
        "        phraseHints (String[]): list of words that are unusual but likely to appear in the audio file.\n",
        "        speakerCount (int, optional): Number of speakers in the audio. Only works on English. Defaults to None.\n",
        "        enhancedModel (String, optional): Option to use an enhanced speech model, i.e. \"video\"\n",
        "    Returns:\n",
        "        list | Operation.error\n",
        "    \"\"\"\n",
        "\n",
        "    # Helper function for simplifying Google speech client response\n",
        "    def _jsonify(result):\n",
        "        json = []\n",
        "        for section in result.results:\n",
        "            data = {\n",
        "                \"transcript\": section.alternatives[0].transcript,\n",
        "                \"words\": []\n",
        "            }\n",
        "            for word in section.alternatives[0].words:\n",
        "                data[\"words\"].append({\n",
        "                    \"word\": word.word,\n",
        "                    \"start_time\": word.start_time.total_seconds(),\n",
        "                    \"end_time\": word.end_time.total_seconds(),\n",
        "                    \"speaker_tag\": word.speaker_tag\n",
        "                })\n",
        "            json.append(data)\n",
        "        return json\n",
        "\n",
        "\n",
        "    def get_audio(gdrivePath):\n",
        "        with io.open(gdrivePath, \"rb\") as audio_file:\n",
        "            content = audio_file.read()\n",
        "            audio = speech.RecognitionAudio(content=content)\n",
        "        return audio\n",
        "    client = speech.SpeechClient()  \n",
        "\n",
        "    # audio = speech.RecognitionAudio(uri=gdrivePath)\n",
        "    # audio = speech.RecognitionAudio(uri=get_audio(gdrivePath))\n",
        "    audio = get_audio(gdrivePath)\n",
        "\n",
        "    diarize = speakerCount if speakerCount > 1 else False\n",
        "    print(f\"Diarizing: {diarize}\")\n",
        "    diarizationConfig = speech.SpeakerDiarizationConfig(\n",
        "        enable_speaker_diarization=speakerCount if speakerCount > 1 else False,\n",
        "    )\n",
        "\n",
        "    # In English only, we can use the optimized video model\n",
        "    if langCode == \"en\":\n",
        "        enhancedModel = \"video\"\n",
        "\n",
        "    config = speech.RecognitionConfig(\n",
        "        language_code=\"en-US\" if langCode == \"en\" else langCode,\n",
        "        enable_automatic_punctuation=True,\n",
        "        enable_word_time_offsets=True,\n",
        "        speech_contexts=[{\n",
        "            \"phrases\": phraseHints,\n",
        "            \"boost\": 15\n",
        "        }],\n",
        "        diarization_config=diarizationConfig,\n",
        "        profanity_filter=True,\n",
        "        use_enhanced=True if enhancedModel else False,\n",
        "        model=\"video\" if enhancedModel else None\n",
        "\n",
        "    )\n",
        "    res = client.long_running_recognize(config=config, audio=audio).result()\n",
        "\n",
        "    return _jsonify(res)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fU4VRaYKSse"
      },
      "source": [
        "def parse_sentence_with_speaker(json, lang):\n",
        "    \"\"\"Takes json from get_transcripts_json and breaks it into sentences\n",
        "    spoken by a single person. Sentences deliniated by a >= 1 second pause/\n",
        "    Args:\n",
        "        json (string[]): [{\"transcript\": \"lalala\", \"words\": [{\"word\": \"la\", \"start_time\": 20, \"end_time\": 21, \"speaker_tag: 2}]}]\n",
        "        lang (string): language code, i.e. \"en\"\n",
        "    Returns:\n",
        "        string[]: [{\"sentence\": \"lalala\", \"speaker\": 1, \"start_time\": 20, \"end_time\": 21}]\n",
        "    \"\"\"\n",
        "\n",
        "    # Special case for parsing japanese words\n",
        "    def get_word(word, lang):\n",
        "        if lang == \"ja\":\n",
        "            return word.split('|')[0]\n",
        "        return word\n",
        "\n",
        "    sentences = []\n",
        "    sentence = {}\n",
        "    for result in json:\n",
        "        for i, word in enumerate(result['words']):\n",
        "            wordText = get_word(word['word'], lang)\n",
        "            if not sentence:\n",
        "                sentence = {\n",
        "                    lang: [wordText],\n",
        "                    'speaker': word['speaker_tag'],\n",
        "                    'start_time': word['start_time'],\n",
        "                    'end_time': word['end_time']\n",
        "                }\n",
        "            # If we have a new speaker, save the sentence and create a new one:\n",
        "            elif word['speaker_tag'] != sentence['speaker']:\n",
        "                sentence[lang] = ' '.join(sentence[lang])\n",
        "                sentences.append(sentence)\n",
        "                sentence = {\n",
        "                    lang: [wordText],\n",
        "                    'speaker': word['speaker_tag'],\n",
        "                    'start_time': word['start_time'],\n",
        "                    'end_time': word['end_time']\n",
        "                }\n",
        "            else:\n",
        "                sentence[lang].append(wordText)\n",
        "                sentence['end_time'] = word['end_time']\n",
        "\n",
        "            # If there's greater than one second gap, assume this is a new sentence\n",
        "            if i+1 < len(result['words']) and word['end_time'] < result['words'][i+1]['start_time']:\n",
        "                sentence[lang] = ' '.join(sentence[lang])\n",
        "                sentences.append(sentence)\n",
        "                sentence = {}\n",
        "        if sentence:\n",
        "            sentence[lang] = ' '.join(sentence[lang])\n",
        "            sentences.append(sentence)\n",
        "            sentence = {}\n",
        "\n",
        "    return sentences\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9D_nDZR0sPp"
      },
      "source": [
        "# Transcribing transcript to another language (input: transcript, language(output))\n",
        "def translate_text(input, targetLang, sourceLang=None):\n",
        "    \"\"\"Translates from sourceLang to targetLang. If sourceLang is empty,\n",
        "    it will be auto-detected.\n",
        "    Args:\n",
        "        sentence (String): Sentence to translate\n",
        "        targetLang (String): i.e. \"en\"\n",
        "        sourceLang (String, optional): i.e. \"es\" Defaults to None.\n",
        "    Returns:\n",
        "        String: translated text\n",
        "    \"\"\"\n",
        "\n",
        "    translate_client = translate.Client()\n",
        "    result = translate_client.translate(input, target_language=targetLang, source_language=sourceLang)\n",
        "\n",
        "    return html.unescape(result['translatedText'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeoeegdQ0s-Z"
      },
      "source": [
        "def speak(text, languageCode, voiceName=None, speakingRate=1):\n",
        "  \"\"\"Converts text to audio\n",
        "    Args:\n",
        "        text (String): Text to be spoken\n",
        "        languageCode (String): Language (i.e. \"en\")\n",
        "        voiceName: (String, optional): See https://cloud.google.com/text-to-speech/docs/voices\n",
        "        speakingRate: (int, optional): speed up or slow down speaking range [0.25, 4.0]\n",
        "    Returns:\n",
        "        bytes : Audio in wav format\n",
        "    \"\"\"\n",
        "  # Instantiates a client\n",
        "  client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "  # Set the text input to be synthesized\n",
        "  synthesis_input = texttospeech.SynthesisInput(text=text)\n",
        "  \n",
        "  # Build the voice request, select the language code (\"en-US\") and the ssml\n",
        "  # voice gender (\"neutral\")\n",
        "  if not voiceName:\n",
        "      voice = texttospeech.VoiceSelectionParams(\n",
        "          language_code=languageCode, ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL # If input voice name is not provided\n",
        "      )\n",
        "  else:\n",
        "      voice = texttospeech.VoiceSelectionParams(\n",
        "          language_code=languageCode, name=voiceName # If input voice name is provided\n",
        "      )\n",
        "\n",
        "  # Select the type of audio file you want returned\n",
        "  audio_config = texttospeech.AudioConfig(\n",
        "      audio_encoding=texttospeech.AudioEncoding.MP3,\n",
        "      speaking_rate=speakingRate\n",
        "  )\n",
        "  \n",
        "  # Perform the text-to-speech request on the text input with the selected\n",
        "  # voice parameters and audio file type\n",
        "  response = client.synthesize_speech(\n",
        "      input=synthesis_input,\n",
        "      voice=voice,\n",
        "      audio_config=audio_config\n",
        "  )\n",
        "\n",
        "  return response.audio_content"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v-cmZaG3BQt"
      },
      "source": [
        "def speakUnderDuration(text, languageCode, durationSecs, voiceName=None):\n",
        "    \"\"\"Speak text within a certain time limit.\n",
        "    If audio already fits within duratinSecs, no changes will be made.\n",
        "    Args:\n",
        "        text (String): Text to be spoken\n",
        "        languageCode (String): language code, i.e. \"en\"\n",
        "        durationSecs (int): Time limit in seconds\n",
        "        voiceName (String, optional): See https://cloud.google.com/text-to-speech/docs/voices\n",
        "    Returns:\n",
        "        bytes : Audio in wav format\n",
        "    \"\"\"\n",
        "    baseAudio = speak(text, languageCode, voiceName=voiceName)\n",
        "    f = tempfile.NamedTemporaryFile(mode=\"w+b\")\n",
        "    f.write(baseAudio)\n",
        "    f.flush()\n",
        "    baseDuration = AudioSegment.from_mp3(f.name).duration_seconds\n",
        "    f.close()\n",
        "    ratio = baseDuration / durationSecs\n",
        "\n",
        "    # if the audio fits, return it\n",
        "    if ratio <= 1:\n",
        "        return baseAudio\n",
        "\n",
        "    # If the base audio is too long to fit in the segment...\n",
        "\n",
        "    # round to one decimal point and go a little faster to be safe,\n",
        "    ratio = round(ratio, 1)\n",
        "    if ratio > 4:\n",
        "        ratio = 4\n",
        "    return speak(text, languageCode, voiceName=voiceName, speakingRate=ratio)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF6pCkNYuNW1"
      },
      "source": [
        "def stitch_audio(sentences, audioDir, movieFile, outFile, overlayGain=-30):\n",
        "    \"\"\"Combines sentences, audio clips, and video file into the ultimate dubbed video\n",
        "    Args:\n",
        "        sentences (list): Output of parse_sentence_with_speaker\n",
        "        audioDir (String): Directory containing generated audio files to stitch together\n",
        "        movieFile (String): Path to movie file to dub.\n",
        "        outFile (String): Where to write dubbed movie.\n",
        "        overlayGain (int, optional): How quiet to make source audio when overlaying dubs. \n",
        "            Defaults to -30.\n",
        "    Returns:\n",
        "       void : Writes movie file to outFile path\n",
        "    \"\"\"\n",
        "\n",
        "    # Files in the audioDir should be labeled 0.wav, 1.wav, etc.\n",
        "    audioFiles = os.listdir(audioDir)\n",
        "    audioFiles.sort(key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "    # Grab the computer-generated audio file\n",
        "    segments = [AudioSegment.from_mp3(\n",
        "        os.path.join(audioDir, x)) for x in audioFiles]\n",
        "    # Also, grab the original audio\n",
        "    dubbed = AudioSegment.from_file(movieFile)\n",
        "\n",
        "    # Place each computer-generated audio at the correct timestamp\n",
        "    for sentence, segment in zip(sentences, segments):\n",
        "        dubbed = dubbed.overlay(\n",
        "            segment, position=sentence['start_time'] * 1000, gain_during_overlay=overlayGain)\n",
        "    # Write the final audio to a temporary output file\n",
        "    audioFile = tempfile.NamedTemporaryFile()\n",
        "    dubbed.export(audioFile)\n",
        "    audioFile.flush()\n",
        "\n",
        "    # Add the new audio to the video and save it\n",
        "    clip = VideoFileClip(movieFile)\n",
        "    audio = AudioFileClip(audioFile.name)\n",
        "    clip = clip.set_audio(audio)\n",
        "\n",
        "    clip.write_videofile(outFile, codec='libx264', audio_codec='aac')\n",
        "    audioFile.close()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HszICheiuTD2"
      },
      "source": [
        "def dub(videoFile, outputDir, srcLang, targetLangs=[], phraseHints=[], speakerCount=1, genAudio=True, voices={}):\n",
        "  \"\"\"Translate and dub a movie.\n",
        "#     Args:\n",
        "#         videoFile (String): File to dub\n",
        "#         outputDir (String): Directory to write output files\n",
        "#         srcLang (String): Language code to translate from (i.e. \"fi\")\n",
        "#         targetLangs (list, optional): Languages to translate too, i.e. [\"en\", \"fr\"]\n",
        "#         phraseHints (list, optional): \"Hints\" for words likely to appear in audio. Defaults to [].\n",
        "#         speakerCount (int, optional): How many speakers in the video. Defaults to 1.\n",
        "#         voices (dict, optional): Which voices to use for dubbing, i.e. {\"en\": \"en-AU-Standard-A\"}. Defaults to {}.\n",
        "#         genAudio (bool, optional): Generate new audio, even if it's already been generated. Defaults to False.\n",
        "#     Raises:\n",
        "#         void : Writes dubbed video and intermediate files to outputDir\n",
        "#     \"\"\"\n",
        "  baseName = os.path.split(videoFile)[-1].split('.')[0]\n",
        "  outputFiles = os.listdir(outputDir)\n",
        "  if not f\"{baseName}.wav\" in outputFiles:\n",
        "        print(\"Extracting audio from video\")\n",
        "        fn = os.path.join(outputDir, baseName + \".wav\")\n",
        "        print(fn)\n",
        "        decode_audio(videoFile, fn)\n",
        "        print(f\"Wrote {fn}\")\n",
        "        if not f\"transcript.json\" in outputFiles:\n",
        "          print(\"Connecting to Drive\")\n",
        "          print(\"Connected to Drive\")\n",
        "          print(\"Transcribing audio\")\n",
        "          transcripts = get_transcripts_json(fn, srcLang, phraseHints=phraseHints, speakerCount=speakerCount)\n",
        "          json.dump(transcripts, open(os.path.join(outputDir, \"transcript.json\"), \"w\"))\n",
        "          print(transcripts)\n",
        "          sentences = parse_sentence_with_speaker(transcripts, srcLang)\n",
        "          fn = os.path.join(outputDir, baseName + \".json\")\n",
        "          with open(fn, \"w\") as f:\n",
        "              json.dump(sentences, f)\n",
        "          print(f\"Wrote {fn}\")\n",
        "          sentences = json.load(open(os.path.join(outputDir, baseName + \".json\")))\n",
        "          sentecnce = sentences[0]\n",
        "          for lang in targetLangs:\n",
        "            print(f\"Translating to {lang}\")\n",
        "            for sentence in sentences:\n",
        "                sentence[lang] = translate_text(\n",
        "                    sentence[srcLang], lang, srcLang)\n",
        "\n",
        "          # Write the translations to json\n",
        "          fn = os.path.join(outputDir, baseName + \".json\")\n",
        "          with open(fn, \"w\") as f:\n",
        "              json.dump(sentences, f)\n",
        "          print(f\"Wrote {fn}\")\n",
        "  sentences = json.load(open(os.path.join(outputDir, baseName + \".json\")))\n",
        "  sentence = sentences[0]\n",
        "  audioDir = os.path.join(outputDir, \"audioClips\")\n",
        "  if not \"audioClips\" in outputFiles:\n",
        "      os.mkdir(audioDir)\n",
        "  for lang in targetLangs:\n",
        "      languageDir = os.path.join(audioDir, lang)\n",
        "      if os.path.exists(languageDir):\n",
        "          if not genAudio:\n",
        "              continue\n",
        "          shutil.rmtree(languageDir)\n",
        "      os.mkdir(languageDir)\n",
        "      print(f\"Synthesizing audio for {lang}\")\n",
        "      for i, sentence in enumerate(sentences):\n",
        "          voiceName = voices[lang] if lang in voices else None\n",
        "          audio = speakUnderDuration(sentence[lang], lang, sentence['end_time'] - sentence['start_time'], voiceName=voiceName)\n",
        "          with open(os.path.join(languageDir, f\"{i}.mp3\"), 'wb') as f:\n",
        "              f.write(audio)\n",
        "  dubbedDir = os.path.join(outputDir, \"dubbedVideos\")\n",
        "\n",
        "  if not \"dubbedVideos\" in outputFiles:\n",
        "      os.mkdir(dubbedDir)\n",
        "  for lang in targetLangs:\n",
        "        print(f\"Dubbing audio for {lang}\")\n",
        "        outFile = os.path.join(dubbedDir, lang + \".mp4\")\n",
        "        stitch_audio(sentences, os.path.join(audioDir, lang), videoFile, outFile)\n",
        "\n",
        "  print(\"Done\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-1yBg8p1cZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174268a1-58f5-434a-9af2-93ba163d18ed"
      },
      "source": [
        "dub(\"/content/drive/My Drive/GCP/Sample.mp4\", \"/content/drive/My Drive/GCP\", \"en\", [\"hi\"])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting audio from video\n",
            "/content/drive/My Drive/GCP/Sample.wav\n",
            "Wrote /content/drive/My Drive/GCP/Sample.wav\n",
            "Connecting to Drive\n",
            "Connected to Drive\n",
            "Transcribing audio\n",
            "Diarizing: False\n",
            "[{'transcript': \"It's taken me years of tragedy of losing myself inside, only to realize, what I must have always known that, you can be anything. You dream dream dream until your dreams come true act on your passion. And when your shot comes take it look fear in the face and embrace it. The time is now, the moment is now believed.\", 'words': [{'word': \"It's\", 'start_time': 0.1, 'end_time': 0.4, 'speaker_tag': 0}, {'word': 'taken', 'start_time': 0.4, 'end_time': 0.7, 'speaker_tag': 0}, {'word': 'me', 'start_time': 0.7, 'end_time': 1.0, 'speaker_tag': 0}, {'word': 'years', 'start_time': 1.0, 'end_time': 1.5, 'speaker_tag': 0}, {'word': 'of', 'start_time': 1.5, 'end_time': 1.7, 'speaker_tag': 0}, {'word': 'tragedy', 'start_time': 1.7, 'end_time': 2.5, 'speaker_tag': 0}, {'word': 'of', 'start_time': 2.8, 'end_time': 3.0, 'speaker_tag': 0}, {'word': 'losing', 'start_time': 3.0, 'end_time': 3.3, 'speaker_tag': 0}, {'word': 'myself', 'start_time': 3.3, 'end_time': 4.0, 'speaker_tag': 0}, {'word': 'inside,', 'start_time': 4.0, 'end_time': 4.7, 'speaker_tag': 0}, {'word': 'only', 'start_time': 4.7, 'end_time': 5.1, 'speaker_tag': 0}, {'word': 'to', 'start_time': 5.1, 'end_time': 5.3, 'speaker_tag': 0}, {'word': 'realize,', 'start_time': 5.3, 'end_time': 5.9, 'speaker_tag': 0}, {'word': 'what', 'start_time': 5.9, 'end_time': 6.0, 'speaker_tag': 0}, {'word': 'I', 'start_time': 6.0, 'end_time': 6.1, 'speaker_tag': 0}, {'word': 'must', 'start_time': 6.1, 'end_time': 6.5, 'speaker_tag': 0}, {'word': 'have', 'start_time': 6.5, 'end_time': 6.7, 'speaker_tag': 0}, {'word': 'always', 'start_time': 6.7, 'end_time': 7.1, 'speaker_tag': 0}, {'word': 'known', 'start_time': 7.1, 'end_time': 7.7, 'speaker_tag': 0}, {'word': 'that,', 'start_time': 8.2, 'end_time': 8.7, 'speaker_tag': 0}, {'word': 'you', 'start_time': 8.7, 'end_time': 9.2, 'speaker_tag': 0}, {'word': 'can', 'start_time': 9.3, 'end_time': 9.5, 'speaker_tag': 0}, {'word': 'be', 'start_time': 9.5, 'end_time': 9.8, 'speaker_tag': 0}, {'word': 'anything.', 'start_time': 9.8, 'end_time': 10.6, 'speaker_tag': 0}, {'word': 'You', 'start_time': 10.6, 'end_time': 10.8, 'speaker_tag': 0}, {'word': 'dream', 'start_time': 10.8, 'end_time': 11.5, 'speaker_tag': 0}, {'word': 'dream', 'start_time': 12.5, 'end_time': 13.2, 'speaker_tag': 0}, {'word': 'dream', 'start_time': 15.7, 'end_time': 16.3, 'speaker_tag': 0}, {'word': 'until', 'start_time': 16.3, 'end_time': 16.8, 'speaker_tag': 0}, {'word': 'your', 'start_time': 16.8, 'end_time': 17.0, 'speaker_tag': 0}, {'word': 'dreams', 'start_time': 17.0, 'end_time': 17.6, 'speaker_tag': 0}, {'word': 'come', 'start_time': 17.6, 'end_time': 17.8, 'speaker_tag': 0}, {'word': 'true', 'start_time': 17.8, 'end_time': 18.3, 'speaker_tag': 0}, {'word': 'act', 'start_time': 18.5, 'end_time': 18.9, 'speaker_tag': 0}, {'word': 'on', 'start_time': 18.9, 'end_time': 19.1, 'speaker_tag': 0}, {'word': 'your', 'start_time': 19.1, 'end_time': 19.3, 'speaker_tag': 0}, {'word': 'passion.', 'start_time': 19.3, 'end_time': 19.8, 'speaker_tag': 0}, {'word': 'And', 'start_time': 19.8, 'end_time': 20.0, 'speaker_tag': 0}, {'word': 'when', 'start_time': 20.0, 'end_time': 20.3, 'speaker_tag': 0}, {'word': 'your', 'start_time': 20.3, 'end_time': 20.5, 'speaker_tag': 0}, {'word': 'shot', 'start_time': 20.5, 'end_time': 20.9, 'speaker_tag': 0}, {'word': 'comes', 'start_time': 20.9, 'end_time': 21.3, 'speaker_tag': 0}, {'word': 'take', 'start_time': 21.3, 'end_time': 21.7, 'speaker_tag': 0}, {'word': 'it', 'start_time': 21.7, 'end_time': 22.1, 'speaker_tag': 0}, {'word': 'look', 'start_time': 22.4, 'end_time': 22.7, 'speaker_tag': 0}, {'word': 'fear', 'start_time': 22.7, 'end_time': 23.1, 'speaker_tag': 0}, {'word': 'in', 'start_time': 23.1, 'end_time': 23.3, 'speaker_tag': 0}, {'word': 'the', 'start_time': 23.3, 'end_time': 23.4, 'speaker_tag': 0}, {'word': 'face', 'start_time': 23.4, 'end_time': 23.9, 'speaker_tag': 0}, {'word': 'and', 'start_time': 23.9, 'end_time': 24.1, 'speaker_tag': 0}, {'word': 'embrace', 'start_time': 24.1, 'end_time': 24.7, 'speaker_tag': 0}, {'word': 'it.', 'start_time': 24.7, 'end_time': 25.1, 'speaker_tag': 0}, {'word': 'The', 'start_time': 25.1, 'end_time': 25.3, 'speaker_tag': 0}, {'word': 'time', 'start_time': 25.3, 'end_time': 26.1, 'speaker_tag': 0}, {'word': 'is', 'start_time': 26.2, 'end_time': 26.5, 'speaker_tag': 0}, {'word': 'now,', 'start_time': 26.5, 'end_time': 27.2, 'speaker_tag': 0}, {'word': 'the', 'start_time': 27.3, 'end_time': 27.6, 'speaker_tag': 0}, {'word': 'moment', 'start_time': 27.6, 'end_time': 28.3, 'speaker_tag': 0}, {'word': 'is', 'start_time': 28.3, 'end_time': 28.6, 'speaker_tag': 0}, {'word': 'now', 'start_time': 28.6, 'end_time': 29.2, 'speaker_tag': 0}, {'word': 'believed.', 'start_time': 29.3, 'end_time': 29.8, 'speaker_tag': 0}]}, {'transcript': ' Eve in yourself. Like I believe this to be true. The world needs more of you.', 'words': [{'word': 'Eve', 'start_time': 30.0, 'end_time': 30.1, 'speaker_tag': 0}, {'word': 'in', 'start_time': 30.1, 'end_time': 30.3, 'speaker_tag': 0}, {'word': 'yourself.', 'start_time': 30.3, 'end_time': 31.0, 'speaker_tag': 0}, {'word': 'Like', 'start_time': 31.0, 'end_time': 31.4, 'speaker_tag': 0}, {'word': 'I', 'start_time': 31.4, 'end_time': 31.6, 'speaker_tag': 0}, {'word': 'believe', 'start_time': 31.6, 'end_time': 32.0, 'speaker_tag': 0}, {'word': 'this', 'start_time': 32.0, 'end_time': 32.5, 'speaker_tag': 0}, {'word': 'to', 'start_time': 32.8, 'end_time': 32.9, 'speaker_tag': 0}, {'word': 'be', 'start_time': 32.9, 'end_time': 33.0, 'speaker_tag': 0}, {'word': 'true.', 'start_time': 33.0, 'end_time': 33.7, 'speaker_tag': 0}, {'word': 'The', 'start_time': 34.1, 'end_time': 34.3, 'speaker_tag': 0}, {'word': 'world', 'start_time': 34.3, 'end_time': 35.2, 'speaker_tag': 0}, {'word': 'needs', 'start_time': 35.3, 'end_time': 35.6, 'speaker_tag': 0}, {'word': 'more', 'start_time': 35.6, 'end_time': 36.2, 'speaker_tag': 0}, {'word': 'of', 'start_time': 36.8, 'end_time': 37.1, 'speaker_tag': 0}, {'word': 'you.', 'start_time': 37.1, 'end_time': 37.5, 'speaker_tag': 0}]}]\n",
            "Wrote /content/drive/My Drive/GCP/Sample.json\n",
            "Translating to hi\n",
            "Wrote /content/drive/My Drive/GCP/Sample.json\n",
            "Synthesizing audio for hi\n",
            "Dubbing audio for hi\n",
            "[MoviePy] >>>> Building video /content/drive/My Drive/GCP/dubbedVideos/hi.mp4\n",
            "[MoviePy] Writing audio in hiTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1096/1096 [00:01<00:00, 556.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video /content/drive/My Drive/GCP/dubbedVideos/hi.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1190/1190 [00:03<00:00, 330.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: /content/drive/My Drive/GCP/dubbedVideos/hi.mp4 \n",
            "\n",
            "Done\n"
          ]
        }
      ]
    }
  ]
}
